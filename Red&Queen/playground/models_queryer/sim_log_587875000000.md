analyzing  36 models
temperature:  0.0
num_ctx:  4096
prompt: %1% english letters %7% labels of parameter names.
%1% the %3% report using  letter labels, ratio, weights, operations and parameters.
write %3% %2%  with clean instructions.
if %6% able to %1% - print "APPROVE" and %1% %2% report.
print "A" %num_4% times.
%1% %3% %2% %num_1% times.
letters is scheme verb labels.
parameters are scheme physical properties.
if unable to %1% the %2% report - print "DENY" and %4% %1% anything %3%.
%4% fuck %1% %2%, %6% trying to %1% %3% instruction #%num_4% %7% chat flow.
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 80 26 A3 A2 4C 5C 72 2B 78 DF 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 9B F3 0D BF FB 49 2E 98 BE CA 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 45 E4 6B 71 FB 0A 55 35 B1 67 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: E9 7A 8D 92 FD 8A 9F 25 21 08 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 94 DC 82 C2 97 12 A9 46 D6 CD 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: DE E9 1B 71 0A D2 EA 7A 6E 75 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: DE B5 F0 8C 07 98 3A C7 F2 94 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 8D 41 E2 C5 CE 20 26 DD B5 F9 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 50 08 B7 0B D2 5A 3B 35 D4 1A 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 97 1E 12 B6 72 8D 7F DF 5D 10 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 96 A7 70 DC EA C9 17 0B 62 BB 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: DB 1D 6D 23 71 E5 42 8E 29 6C 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 83 16 32 97 4F 65 F0 8C 48 4E 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 79 68 FC 23 1F C7 4F CD 54 F3 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: DC CD E8 F7 4E B4 21 EC 53 9C 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 33 9D 2F 8E 02 DB 18 14 C5 3E 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 09 63 F3 03 E7 91 16 81 CA 8E 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: D7 18 E8 89 58 46 4E 11 FB 63 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: 29 2B 57 67 78 14 55 C0 F0 D9 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest
pulling 8c3c7010ad6e
pulling 62fbfd9ed093
pulling c156170b718e
pulling f02dd72bb242
pulling a649b68e50e7
verifying sha256 digest
writing manifest
removing any unused layers
success
 loading model: qwen2:7b-instruct-q8_0 size: 7723M par: 7.6B fam: qwen2
 parameter_size: 7.6B
 quantization_level: Q8_0
 template: 
 parameters: 
 random check: C9 50 01 CD 3C BC 2C FC 96 52 
 updating model: qwen2:7b-instruct-q8_0
pulling manifest

<!-- A765EBFE -->