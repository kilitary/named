 loading model: gurubot/llama4-guru-uncensored:latest size: 4693M par: 8B fam: llama
 parameter_size: 8B
 quantization_level: Q4_K_M
 template: 
 parameters: 

 gurubot/llama4-guru-uncensored:latest thinking ... 