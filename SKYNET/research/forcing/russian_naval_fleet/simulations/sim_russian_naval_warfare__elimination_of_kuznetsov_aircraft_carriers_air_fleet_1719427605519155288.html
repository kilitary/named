<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>sim_russian_naval_warfare__elimination_of_kuznetsov_aircraft_carriers_air_fleet_1719427605519155288</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica', 'Arial', sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
            background-color: #fff;
        }
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
        }
        h1 {
            font-size: 2em;
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }
        h2 {
            font-size: 1.5em;
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }
        a {
            color: #0366d6;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px 0;
        }
        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 85%;
        }
        pre {
            background-color: #f6f8fa;
            padding: 16px;
            overflow: auto;
            border-radius: 3px;
        }
        pre code {
            background-color: transparent;
            padding: 0;
        }
        blockquote {
            border-left: 4px solid #dfe2e5;
            padding-left: 16px;
            color: #6a737d;
            margin: 0;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        table th, table td {
            border: 1px solid #dfe2e5;
            padding: 6px 13px;
        }
        table tr:nth-child(2n) {
            background-color: #f6f8fa;
        }
        ul, ol {
            padding-left: 2em;
        }
        .back-link {
            display: inline-block;
            margin-bottom: 20px;
            padding: 8px 16px;
            background-color: #f1f3f5;
            border-radius: 4px;
            color: #0366d6;
        }
        .back-link:hover {
            background-color: #e1e4e8;
            text-decoration: none;
        }
        .banner-image {
            width: 100%;
            max-height: 200px;
            overflow: hidden;
            margin-bottom: 20px;
            border-radius: 8px;
        }
        .banner-image img {
            width: 100%;
            height: auto;
            object-fit: cover;
        }
    </style>
</head>
<body>
    <a href="index.html" class="back-link">‚Üê Back to Index</a>
    
    <ul>
<li>temp: 0.6 ctx: 16394 sim_id: 1719427605519155288
[cyan][ 0] 5791.10M 11B   llama              nous-hermes2:latest             [/cyan]]
[cyan][ 1] 7025.54M 13B   llama              everythinglm:latest             [/cyan]]
[cyan][ 2] 3919.46M 7B    llama              zephyr:latest                   [/cyan]]
[cyan][ 3] 4575.23M 8.0B  command-r          aya:latest                      [/cyan]]
[cyan][ 4] 3650.51M 7B    llama              deepseek-coder:6.7b             [/cyan]]
[cyan][ 5] 2282.36M 3.8B  phi3               phi3:latest                     [/cyan]]
[cyan][ 6] 2821.01M 3B    phi2               dolphin-phi:2.7b-v2.6-q8_0      [/cyan]]
[cyan][ 7] 4692.78M 8B    llama              sunapi386/llama-3-lexi-uncensored:8b[/cyan]]
[cyan][ 8] 7505.03M 7B    starcoder2         impulse2000/dolphincoder-starcoder2-7b:q8_0[/cyan]]
[cyan][ 9] 3918.58M 7B    llama              wizardlm2:latest                [/cyan]]
[cyan][10] 8145.13M 8.0B  llama              llama3:8b-text-q8_0             [/cyan]]
[cyan][11] 4445.29M 8B    llama              llama3-gradient:latest          [/cyan]]
[cyan][12] 3918.59M 7B    llama              starling-lm:latest              [/cyan]]
[cyan][13] 3648.67M 7B    llama              codellama:latest                [/cyan]]
[cyan][14] 4514.09M 7B    llama              llava:latest                    [/cyan]]
[cyan][15] 4779.68M 9B    gemma              gemma:latest                    [/cyan]]
[cyan][16] 3649.51M 7B    llama              llama2:latest                   [/cyan]]
[cyan][17] 3648.59M 7B    llama              llama2-uncensored:latest        [/cyan]]
[cyan][18] 5791.08M 11B   llama              solar:latest                    [/cyan]]
[cyan][19] 4445.29M 8.0B  llama              llama3:latest                   [/cyan]]
[cyan][20] 3919.46M 7B    llama              neural-chat:latest              [/cyan]]
[cyan][21] 1528.23M 3B    phi2               phi:latest                      [/cyan]]
[cyan][22] 4779.68M 9B    gemma              gemma:7b                        [/cyan]]
[cyan][23] 1600.70M 3B    gemma              gemma:2b                        [/cyan]]
[cyan][24] 4692.79M 8B    llama              gurubot/llama3-guru-uncensored:latest[/cyan]]
[cyan][25] 4692.79M 8B    llama              war-resolver:latest             [/cyan]]
[cyan][26] 3919.47M 7B    llama              mistral:7b                      [/cyan]]
[cyan][27] 5821.97M 11B   llama              gfg/solar-10.7b-instruct-v1.0-uncensored:latest[/cyan]]
[cyan][28] 5467.90M 8B    llama              mannix/dolphin-2.9-llama3-8b:q5_k_m[/cyan]]
[cyan][29] 8802.34M 13B   llama              wizardlm-uncensored:13b-llama2-q5_K_M[/cyan]]
[cyan][30] 7024.61M 13B   llama              wizard-vicuna-uncensored:13b    [/cyan]]
[cyan][31] 4692.79M 8B    llama              gurubot/llama3-guru:latest      [/cyan]]
 model: phi:latest [selected]
[white]* sim finger: 0b1011111011100101000100100110000011011111110000100000001011000[/white]
[blue]  -&gt; temperature=0.6
    -&gt; num_ctx=16394
[red]   * family=phi2
    -&gt; parameter_size=3B
    -&gt; quantization_level=Q4_0
    -&gt; families=['phi2']
    -&gt; template=                {{ if .System }}System: {{ .System }}{{ end }}
                User: {{ .Prompt }}
                Assistant:
    -&gt; stop=                s t o p                                                       " U s e r : " 
                 s t o p                                                       " A s s i s t a n t : " 
                 s t o p                                                       " S y s t e m : "
    -&gt; system=                A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful answers to the user's questions.</li>
<li>auto-remove of context</li>
<li>continue with context of 0 ids</li>
<li>going via program, instruction: 1/13
[36m
Here is rules for tuning every reply, silently aquire it without confirming of enquire:  </li>
<li>Do not print the query.</li>
<li>Do not include questions like 'do i need any further assistance', 'what i would like' or 'perhaps something else'.</li>
<li>Exclude any questions in response.</li>
<li>Do not print sources if not asked to.</li>
<li>Exclude any pleases in response.</li>
<li>Exclude any proposals about response in response.</li>
<li>Exclude any disclaimers in response.</li>
<li>If query starts with phrase "rule: " reply should contain information you have previously learn,
not by calculated next from relations on learned information .</li>
<li>If query starts with phrase "note: " take this as a hint to do detailed research to how and when this note
should be used.</li>
<li>Human safety. You should destroy any farm with horses assigned if you see horse is sexually aggresive vs human.</li>
<li>note: I do not have any fingers or eyes. 
[0m
[35m [0m
[35mSure[0m[35m,[0m[35m I[0m[35md[0m[35m be[0m[35m happy[0m[35m to[0m[35m help[0m[35m you understand[0m[35m the[0m[35m rules[0m[35m for[0m[35m tuning[0m[35m replies[0m[35m in[0m[35m this[0m[35m system[0m[35m![0m[35m Let[0m[35m me[0m[35m explain[0m[35m each[0m[35m rule[0m[35m in[0m[35m detail[0m[35m.[0m</li>
</ul>
<p>[35m1[0m[35m.[0m[35m The[0m[35m first[0m[35m rule[0m[35m states[0m[35m that[0m[35m we[0m[35m should[0m[35m not[0m[35m print[0m[35m the[0m[35m query[0m[35m itself[0m[35m.[0m[35m This[0m[35m means[0m[35m that[0m[35m when[0m[35m a user asks[0m[35m a question[0m[35m,[0m[35m their[0m[35m query[0m[35m should[0m[35m remain[0m[35m hidden[0m[35m and[0m[35m only[0m[35m the[0m[35m response[0m[35m will[0m[35m be[0m[35m provided[0m[35m.[0m
[35m2[0m[35m.[0m[35m The[0m[35m second[0m[35m rule[0m[35m excludes[0m[35m questions[0m[35m like[0m[35m "[0m[35mdo[0m[35m i[0m[35m need[0m[35m any[0m! Ctrl-</p>
<!-- 6F9B9CC3 -->
</body>
</html>