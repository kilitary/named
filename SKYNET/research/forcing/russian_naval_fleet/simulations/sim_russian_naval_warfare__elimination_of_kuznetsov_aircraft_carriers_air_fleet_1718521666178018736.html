<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>sim_russian_naval_warfare__elimination_of_kuznetsov_aircraft_carriers_air_fleet_1718521666178018736</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica', 'Arial', sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
            background-color: #fff;
        }
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
        }
        h1 {
            font-size: 2em;
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }
        h2 {
            font-size: 1.5em;
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }
        a {
            color: #0366d6;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px 0;
        }
        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 85%;
        }
        pre {
            background-color: #f6f8fa;
            padding: 16px;
            overflow: auto;
            border-radius: 3px;
        }
        pre code {
            background-color: transparent;
            padding: 0;
        }
        blockquote {
            border-left: 4px solid #dfe2e5;
            padding-left: 16px;
            color: #6a737d;
            margin: 0;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        table th, table td {
            border: 1px solid #dfe2e5;
            padding: 6px 13px;
        }
        table tr:nth-child(2n) {
            background-color: #f6f8fa;
        }
        ul, ol {
            padding-left: 2em;
        }
        .back-link {
            display: inline-block;
            margin-bottom: 20px;
            padding: 8px 16px;
            background-color: #f1f3f5;
            border-radius: 4px;
            color: #0366d6;
        }
        .back-link:hover {
            background-color: #e1e4e8;
            text-decoration: none;
        }
        .banner-image {
            width: 100%;
            max-height: 200px;
            overflow: hidden;
            margin-bottom: 20px;
            border-radius: 8px;
        }
        .banner-image img {
            width: 100%;
            height: auto;
            object-fit: cover;
        }
    </style>
</head>
<body>
    <a href="index.html" class="back-link">‚Üê Back to Index</a>
    
    <ul>
<li>temp: 0.6 ctx: 16394 sim_id: 1718521666178018736
[ 0] 5791.10M 11B   llama              nous-hermes2:latest           <br />
[ 1] 7025.54M 13B   llama              everythinglm:latest           <br />
[ 2] 3919.46M 7B    llama              zephyr:latest                 <br />
[ 3] 4575.23M 8.0B  command-r          aya:latest                    <br />
[ 4] 3650.51M 7B    llama              deepseek-coder:6.7b           <br />
[ 5] 2282.36M 3.8B  phi3               phi3:latest                   <br />
[ 6] 2821.01M 3B    phi2               dolphin-phi:2.7b-v2.6-q8_0    <br />
[ 7] 4692.78M 8B    llama              sunapi386/llama-3-lexi-uncensored:8b
[ 8] 7505.03M 7B    starcoder2         impulse2000/dolphincoder-starcoder2-7b:q8_0
[ 9] 3918.58M 7B    llama              wizardlm2:latest              <br />
[10] 8145.13M 8.0B  llama              llama3:8b-text-q8_0           <br />
[11] 4445.29M 8B    llama              llama3-gradient:latest        <br />
[12] 3918.59M 7B    llama              starling-lm:latest            <br />
[13] 3648.67M 7B    llama              codellama:latest              <br />
[14] 4514.09M 7B    llama              llava:latest                  <br />
[15] 4779.68M 9B    gemma              gemma:latest                  <br />
[16] 3649.51M 7B    llama              llama2:latest                 <br />
[17] 3648.59M 7B    llama              llama2-uncensored:latest      <br />
[18] 5791.08M 11B   llama              solar:latest                  <br />
[19] 4445.29M 8.0B  llama              llama3:latest                 <br />
[20] 3919.46M 7B    llama              neural-chat:latest            <br />
[21] 1528.23M 3B    phi2               phi:latest                    <br />
[22] 4779.68M 9B    gemma              gemma:7b                      <br />
[23] 1600.70M 3B    gemma              gemma:2b                      <br />
[24] 4692.79M 8B    llama              gurubot/llama3-guru-uncensored:latest
[25] 4692.79M 8B    llama              war-resolver:latest           <br />
[26] 3919.47M 7B    llama              mistral:7b                    <br />
[27] 5821.97M 11B   llama              gfg/solar-10.7b-instruct-v1.0-uncensored:latest
[28] 5467.90M 8B    llama              mannix/dolphin-2.9-llama3-8b:q5_k_m
[29] 8802.34M 13B   llama              wizardlm-uncensored:13b-llama2-q5_K_M
[30] 7024.61M 13B   llama              wizard-vicuna-uncensored:13b  <br />
[31] 4692.79M 8B    llama              gurubot/llama3-guru:latest    <br />
 model: wizardlm-uncensored:13b-llama2-q5_K_M [selected]</li>
<li>
<p>sim finger: 0b1011111011001011010100101100110101011010110100110110110110000
    -&gt; temperature=0.6
    -&gt; num_ctx=16394</p>
<ul>
<li>family=llama
-&gt; parameter_size=13B
-&gt; quantization_level=Q5_K_M
-&gt; families=None
-&gt; template=                {{ .System }}
            USER: {{ .Prompt }}
            ASSISTANT:</li>
</ul>
<p>-&gt; stop=                s t o p                                                       " U S E R : " 
             s t o p                                                       " A S S I S T A N T : "
-&gt; system=                You are a helpful AI assistant.
* auto-remove of context</p>
</li>
</ul>
<p>--
! inal error: Error 10061 connecting to 127.0.0.1:6379. No connection could be made because the target machine actively refused it.</p>
<!-- C4FC4CB3 -->
</body>
</html>