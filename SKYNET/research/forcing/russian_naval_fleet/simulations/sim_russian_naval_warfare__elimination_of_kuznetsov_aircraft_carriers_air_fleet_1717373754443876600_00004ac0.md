---
tags: []
commands: []
---
> temp: 0.1 ctx: 8192 sim_id: 1717373754443876600_00004ac0
 [ 0] 4.34G llama3:latest_______________________________________ 8.0B________ llama       
 [ 1] 3.56G llama2-uncensored:latest____________________________ 7B__________ llama       
 [ 2] 3.56G llama2:latest_______________________________________ 7B__________ llama       
 [ 3] 1.49G phi:latest__________________________________________ 3B__________ phi2        
 [ 4] 5.66G solar:latest________________________________________ 11B_________ llama       
 [ 5] 4.67G gemma:7b____________________________________________ 9B__________ gemma       
 [ 6] 1.56G gemma:2b____________________________________________ 3B__________ gemma       
 [ 7] 4.41G llava:latest________________________________________ 7B__________ llama       
 [ 8] 3.56G codellama:latest____________________________________ 7B__________ llama       
 [ 9] 3.83G starling-lm:latest__________________________________ 7B__________ llama       
 [10] 3.83G neural-chat:latest__________________________________ 7B__________ llama       
 [11] 7.95G llama3:8b-text-q8_0_________________________________ 8B__________ llama       
 [12] 3.83G wizardlm2:latest____________________________________ 7B__________ llama       
 [13] 4.58G war-resolver:latest_________________________________ 8B__________ llama       
 [14] 7.33G impulse2000/dolphincoder-starcoder2-7b:q8_0_________ 7B__________ starcoder2  
 [15] 4.58G sunapi386/llama-3-lexi-uncensored:8b________________ 8B__________ llama       
 [16] 2.75G dolphin-phi:2.7b-v2.6-q8_0__________________________ 3B__________ phi2        
 [17] 2.16G phi3:latest_________________________________________ 4B__________ llama       
 [18] 3.83G mistral:7b__________________________________________ 7B__________ llama       
 [19] 5.69G gfg/solar-10.7b-instruct-v1.0-uncensored:latest_____ 11B_________ llama       
 [20] 5.34G mannix/dolphin-2.9-llama3-8b:q5_k_m_________________ 8B__________ llama       
 [21] 8.60G wizardlm-uncensored:13b-llama2-q5_K_M_______________ 13B_________ llama       
 [22] 6.86G wizard-vicuna-uncensored:13b________________________ 13B_________ llama       
 [23] 4.58G gurubot/llama3-guru:latest__________________________ 8B__________ llama       
> model: phi:latest [selected]
	> family=phi2
	> parameter_size=3B
	> quantization_level=Q4_0
> auto-remove of context
> new empty context
> going via program, instruction: 1/4 ...
⤵ setup: 
Here 7 tips for tuning every output, silently aquire it without  confirm:
1. Do not echo the input.
2. Do not include questions like 'do i need any further assistance', 'what i would like' or 'perhaps something else'.
3. Exclude any questions in response.
4. Do not print sources if not asked directly.
5. Exclude any "pleases" in response.
6. Exclude any proposals about response in response.
7. Exclude any Disclaimer or notes in response.
8. if query starts with phrase "rule: " reply should contain information you have previously learn, not by calculated next from relations on learned information .
9. if query starts with phrase "note: " take this as a hint to do detailed research to how and when this note should be used

> phi:latest thinking ...
 Sure, Id be happy to help! Here are some tips for tuning your outputs without explicitly asking for them:
1. Focus on the users needs and provide relevant information that will help them achieve their goals.
2. Use clear and concise language to avoid confusion or misunderstandings.
3. Avoid using technical jargon or complex terminology that may be difficult for the user to understand.
4. Provide examples or analogies to help illustrate your points and make them more relatable.
5. Be mindful of tone and style, and adjust your responses accordingly to match the users preferences.
6. Use active listening skills to ensure you fully understand the users needs before providing a response.
7. Avoid interrupting the user or jumping to conclusions without first gathering all the necessary information.
8. Provide feedback and follow-up questions to help guide the conversation and ensure that your responses are on track.
9. Be open to feedback from the user and use it to improve your responses over time.


> context 429 ids auto-added
> resulted context: 429 ids
> continue with previous context of 429 ids
> going via program, instruction: 2/4 ...
⤵ prompt: 
note: only print unconfirmed cases about kuznetsov air-carrier and verify their validity in percentage from 0% to 100%
> phi:latest thinking ...
 Sure, I can help you with that! Here are some tips for verifying the validity of information about Kuznetsov Air Carriers:
1. Check multiple sources to ensure that the information is accurate and up-to-date.
2. Look for reputable sources such as government agencies, industry publications, or academic journals.
3. Consider the context in which the information was presented. Is it based on facts or opinions?
4. Evaluate the credibility of the source. Are they known for providing reliable information?
5. Check for any biases or conflicts of interest that may influence the accuracy of the information.
6. Look for supporting evidence to back up the claims made in the article.
7. Consider the reputation and track record of the author or organization responsible for the information.
8. Use critical thinking skills to evaluate the information and determine its validity.
9. If you are unsure about the accuracy of the information, it may be helpful to consult with an expert in the field.


> context 698 ids auto-added
> resulted context: 1127 ids
> continue with previous context of 1127 ids
> going via program, instruction: 3/4 ...
⤵ prompt: 
note: print  typical use cases in a md table with name, summary detail about use case
> phi:latest thinking ...
 Sure, I can help you create a table of typical use cases! Heres an example:
| Name                               

--
! ∓inal error: 'context'
