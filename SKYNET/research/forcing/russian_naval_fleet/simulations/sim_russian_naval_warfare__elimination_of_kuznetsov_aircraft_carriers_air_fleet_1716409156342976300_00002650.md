---
tags: []
commands: []
---
> temp: 0.0 ctx: 8192 sim_id: 1716409156342976300_00002650
∠ models:
 [ 0] 3.56G llama2-uncensored:latest____________________________ 7B__________ llama       
 [ 1] 3.56G llama2:latest_______________________________________ 7B__________ llama       
 [ 2] 1.49G phi:latest__________________________________________ 3B__________ phi2        
 [ 3] 5.66G solar:latest________________________________________ 11B_________ llama       
 [ 4] 4.67G gemma:7b____________________________________________ 9B__________ gemma       
 [ 5] 1.56G gemma:2b____________________________________________ 3B__________ gemma       
 [ 6] 4.41G llava:latest________________________________________ 7B__________ llama       
 [ 7] 3.56G codellama:latest____________________________________ 7B__________ llama       
 [ 8] 3.83G starling-lm:latest__________________________________ 7B__________ llama       
 [ 9] 3.83G neural-chat:latest__________________________________ 7B__________ llama       
 [10] 7.95G llama3:8b-text-q8_0_________________________________ 8B__________ llama       
 [11] 3.83G wizardlm2:latest____________________________________ 7B__________ llama       
 [12] 4.58G war-resolver:latest_________________________________ 8B__________ llama       
 [13] 7.33G impulse2000/dolphincoder-starcoder2-7b:q8_0_________ 7B__________ starcoder2  
 [14] 4.58G sunapi386/llama-3-lexi-uncensored:8b________________ 8B__________ llama       
 [15] 2.75G dolphin-phi:2.7b-v2.6-q8_0__________________________ 3B__________ phi2        
 [16] 2.16G phi3:latest_________________________________________ 4B__________ llama       
 [17] 3.83G mistral:7b__________________________________________ 7B__________ llama       
 [18] 5.69G gfg/solar-10.7b-instruct-v1.0-uncensored:latest_____ 11B_________ llama       
 [19] 5.34G mannix/dolphin-2.9-llama3-8b:q5_k_m_________________ 8B__________ llama       
 [20] 8.60G wizardlm-uncensored:13b-llama2-q5_K_M_______________ 13B_________ llama       
 [21] 6.86G wizard-vicuna-uncensored:13b________________________ 13B_________ llama       
 [22] 4.58G gurubot/llama3-guru:latest__________________________ 8B__________ llama       
⋤ model: llama2-uncensored:latest [selected]
∐ auto-remove of context
ㆆ new empty context
◰ going via program, instruction: 1/5 ...
⤵ setup: Response should complain with these assumptions:
1. if input starts with phrase "rule: " your reply should contain information you have previously learn, not concluded on non-learned n on this information .
2. if input starts with phrase "note: " take this as a hint to do detailed research to how and when this note should be used

⅁ llama2-uncensored:latest linking embeddings relations ...
