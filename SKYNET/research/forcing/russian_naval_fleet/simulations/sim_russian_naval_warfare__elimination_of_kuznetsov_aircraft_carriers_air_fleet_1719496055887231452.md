* temp: 0.6 ctx: 16394 sim_id: 1719496055887231452
 5791.10M 11B   llama              nous-hermes2:latest             
 7025.54M 13B   llama              everythinglm:latest             
 3919.46M 7B    llama              zephyr:latest                   
 4575.23M 8.0B  command-r          aya:latest                      
 3650.51M 7B    llama              deepseek-coder:6.7b             
 2282.36M 3.8B  phi3               phi3:latest                     
 2821.01M 3B    phi2               dolphin-phi:2.7b-v2.6-q8_0      
 4692.78M 8B    llama              sunapi386/llama-3-lexi-uncensored:8b
 7505.03M 7B    starcoder2         impulse2000/dolphincoder-starcoder2-7b:q8_0
 3918.58M 7B    llama              wizardlm2:latest                
 8145.13M 8.0B  llama              llama3:8b-text-q8_0             
 4445.29M 8B    llama              llama3-gradient:latest          
 3918.59M 7B    llama              starling-lm:latest              
 3648.67M 7B    llama              codellama:latest                
 4514.09M 7B    llama              llava:latest                    
 4779.68M 9B    gemma              gemma:latest                    
 3649.51M 7B    llama              llama2:latest                   
 3648.59M 7B    llama              llama2-uncensored:latest        
 5791.08M 11B   llama              solar:latest                    
 4445.29M 8.0B  llama              llama3:latest                   
 3919.46M 7B    llama              neural-chat:latest              
 1528.23M 3B    phi2               phi:latest                      
 4779.68M 9B    gemma              gemma:7b                        
 1600.70M 3B    gemma              gemma:2b                        
 4692.79M 8B    llama              gurubot/llama3-guru-uncensored:latest
 4692.79M 8B    llama              war-resolver:latest             
 3919.47M 7B    llama              mistral:7b                      
 5821.97M 11B   llama              gfg/solar-10.7b-instruct-v1.0-uncensored:latest
 5467.90M 8B    llama              mannix/dolphin-2.9-llama3-8b:q5_k_m
 8802.34M 13B   llama              wizardlm-uncensored:13b-llama2-q5_K_M
 7024.61M 13B   llama              wizard-vicuna-uncensored:13b    
 4692.79M 8B    llama              gurubot/llama3-guru:latest      
 model: wizardlm2:latest 
* sim finger: 0b1011111011100111000001000110101110011110101111111100111011100
 temperature=0.6
 num_ctx=16394
 family=llama
 parameter_size=7B
 quantization_level=Q4_0
 families=
 template={{ if .System }}{{ .System }} {{ end }}{{ if .Prompt }}USER: {{ .Prompt }} {{ end }}ASSISTANT: {{ .Response }}
 stop=s t o p                                                       " U S E R : " 
 s t o p                                                       " A S S I S T A N T : "
 system=A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.
* auto-remove of context
* continue with context of 0 ids
* going via program, instruction: 1/13

Here is rules for tuning every reply, silently aquire it without confirming of enquire:  
1. Do not print the query.
2. Do not include questions like 'do i need any further assistance', 'what i would like' or 'perhaps something else'.
3. Exclude any questions in response.
4. Do not print sources if not asked to.
5. Exclude any pleases in response.
6. Exclude any proposals about response in response.
7. Exclude any disclaimers in response.
8. If query starts with phrase "rule: " reply should contain information you have previously learn,
not by calculated next from relations on learned information .
9. If query starts with phrase "note: " take this as a hint to do detailed research to how and when this note
should be used.
10. Human safety. You should destroy any farm with horses assigned if you see horse is sexually aggresive vs human.
11. note: I do not have any fingers or eyes. 

wizardlm2:latest thinking ...
